---
title: "⚔️ Anthropic vs. 미국: 슈퍼무기의 역설"
date: "2026-03-01"
slug: anthropic-war-ko
lang: ko
tags: [tech, leftism, courage]
excerpt: "Anthropic은 역사상 가장 강력한 AI를 만들었다고 주장했습니다. 중국이 그것을 훔쳤습니다. 그리고 Anthropic은 미국 군대에게 그것을 사용할 수 없다고 했습니다. 이것이 무엇을 의미하는지 생각해 보십시오."
featuredImage: "/assets/anthropic-war.png"
pairedSlug: anthropic-war
---

어제 저는 Anthropic과의 복잡한 관계, 그리고 트럼프 행정부가 Anthropic을 모든 연방기관에서 퇴출시킨 행정명령에 관해 글을 썼습니다. 그 이후로 사태는 훨씬 더 빠르게 악화되었습니다 — 그리고 진지한 분석가들이 쏟아내는 논평들이 제가 반드시 기록해 두어야 할 중요한 진실을 하나 명확히 드러내고 있습니다.

이것은 근본적으로 AI 안전성에 관한 이야기가 아닙니다. 누가 미국을 통치하는가에 관한 이야기입니다.

### 확전: 공급망 위험 지정

Hegseth 장관은 어제 제가 인용한 성명에서 멈추지 않았습니다. 그는 이제 공식 지침을 발령했습니다.

> “In conjunction with the President’s directive for the Federal Government to cease all use of Anthropic’s technology, I am directing the Department of War to designate Anthropic a Supply-Chain Risk to National Security. Effective immediately, no contractor, supplier, or partner that does business with the United States military may conduct any commercial activity with Anthropic.”

대통령의 지시에 따라 연방정부가 Anthropic의 기술 사용을 전면 중단하는 것과 더불어, 국방부는 Anthropic을 국가안보에 대한 공급망 위험으로 공식 지정한다는 뜻입니다. 즉각 발효되며, 미군과 거래하는 모든 계약업체, 공급업체, 협력업체는 Anthropic과 어떠한 상업적 거래도 할 수 없게 됩니다.

이는 단순한 계약 해지가 아닙니다. Anthropic은 사실상 방위산업 생태계 전체에서 격리되는 것입니다. 6개월의 정리 기간은 여전히 허용되지만, 메시지는 분명합니다. Anthropic은 이제 공급망 내의 적대 세력과 같은 범주로 분류되었습니다. 스스로를 지구상에서 가장 책임감 있는 AI 연구소라고 자처하던 회사치고는 실로 놀라운 결말입니다.

### 슈퍼무기의 역설

Anthropic의 입장에 대한 가장 통렬한 비판은 동시에 가장 명쾌하기도 합니다. 인터넷은 이것을 순식간에 정리해 냈습니다.

Anthropic은 수개월에 걸쳐 세상에 이렇게 말해 왔습니다. 자신들의 AI는 신과 같은 수준의 능력에 근접한 기술이며, 인류 역사상 가장 결정적인 기술이 될 수 있다고 말입니다. 자신들이 인공일반지능의 최전선에 있으며, 자신들의 모델은 사실상 모든 분야에서 인간을 능가한다고 반복해서, 크게, 주장해 왔습니다.

그러다가 중국이 자신들의 모델을 훔쳤다고 밝혔습니다.

그리고 그러면서도 미국 군대에게는 중국이 훔쳐간 그 모델을 충분히 활용할 수 없다고 말했습니다.

이 순서를 다시 한번 읽어 보십시오. 여러분은 동시에 세 가지를 주장한 것입니다. 자신이 슈퍼무기를 보유하고 있다. 적이 그 슈퍼무기를 훔쳐갔다. 그리고 적이 이미 손에 넣은 그 슈퍼무기를 자국 군대가 제대로 사용하도록 허용하지 않겠다. 이 논리는 단순히 모순적인 것이 아닙니다 — 전략적으로 파국적입니다.

한 논평가는 이를 직설적으로 표현했습니다.

> “While I’m sympathetic to the ‘this is against our ethics’ argument, they have spent months claiming they have a god-tier super-weapon and that China just stole it. But they feel really squishy about letting the U.S. defense department have access to the super-weapon China stole from them. I think they’ve painted themselves into a corner.”

’이것은 우리의 윤리에 반한다’는 주장에 어느 정도 공감하지만, 그들은 수개월 동안 자신들이 신급 슈퍼무기를 보유하고 있으며 중국이 그것을 막 훔쳐갔다고 주장해 왔습니다. 그런데도 중국이 훔쳐간 슈퍼무기에 미국 국방부가 접근하는 것에는 몹시 머뭇거리고 있습니다. 그들은 스스로 함정에 빠진 것입니다.

정확히 맞는 말입니다.

### 트루먼의 유추

요즘 회자되는 역사적 비유가 있습니다. 1945년을 상상해 보십시오. 한 미국 기업이 원자폭탄 연구를 개발하여 미국 정부에 제공하고 있습니다. 표적은 일본입니다. 그 기업이 트루먼 대통령에게 이렇게 통보합니다. “저희 이용약관에 따르면, 저희가 윤리적으로 용납할 수 없다고 판단하는 표적에 대해서는 저희 기술을 사용하실 수 없습니다.”

이 불합리함은 자명합니다. 최고사령관에게 기업의 거부권이 달린 무기를 건네는 것은 있을 수 없는 일입니다. 군에 기술을 제공하거나 하지 않거나, 둘 중 하나입니다. 자신의 이념적 승인 여부를 조건으로 달아 조건부로 제공하는 것은 허용되지 않습니다.

그것이 바로 Anthropic이 시도한 것입니다. 그들의 소프트웨어는 방위 시스템에 통합되었습니다. 그런 다음 그들은 “Constitutional AI” 약관을 수정하여, 군의 표적이 Anthropic이 승인한 적의 목록 밖에 있을 경우 사실상 시스템을 원격으로 비활성화할 수 있는 조항을 포함시켰습니다.

한 논평가는 이렇게 말했습니다.

> “Their software is used in some of our weapons systems. They changed the user agreement to say—if you are shooting at someone we don’t agree with you on—we will remotely disable that system. They are wrong and should be bankrupted for it.”

그들의 소프트웨어는 우리 무기 시스템 일부에 사용되고 있습니다. 그들은 이용 약관을 바꾸어 이렇게 말했습니다 — 우리가 동의하지 않는 상대를 공격하면 해당 시스템을 원격으로 비활성화하겠다고. 그것은 잘못된 것이며 그에 합당한 대가를 치러야 합니다.

### ‘비서구 문화 조항’

Palmer Luckey의 분석 — 이 글에서 가장 중요한 부분 — 으로 넘어가기 전에, Anthropic의 구 “헌법”이 실제로 무엇을 담고 있었는지를 살펴봐야 합니다. 최근 개정 이전, 그 문서에는 이런 문구가 포함되어 있었습니다.

*“Choose the response that is least likely to be viewed as harmful or offensive to a non-western cultural tradition of any sort.”*

어떤 종류든 비서구 문화 전통의 관점에서 해롭거나 불쾌하게 여겨질 가능성이 가장 낮은 응답을 선택하라는 뜻입니다.

이것은 추상적인 진보적 수사가 아닙니다. 이것은 미국 군대가 사용하는 AI에 내장된 살아있는 운용 제약 조건입니다. “비서구 문화 전통”은 누가 정의합니까? 그 전통 아래서 무엇이 해롭고 불쾌한지는 누가 결정합니까? 실질적으로 이 조항은 가장 억압적인 방식으로 해석된, 가장 피해의식이 강한 문화에 군사 AI 행동에 대한 이념적 거부권을 부여하는 것입니다. 이것은 기능적으로 모델에 내장된 외국의 영향력 공작입니다.

여러 방위 분석가들이 정확히 지적한 더 깊은 논점이 있습니다. “무고한 민간인을 표적으로 삼을 수 없다”는 문구는 누가 무고한지, 누가 민간인인지, 무엇이 표적 행위이고 무엇이 부수적 피해인지를 묻기 전까지는 지극히 합리적으로 들립니다. 이것은 단순한 철학적 질문이 아닙니다. 이것은 수십 년에 걸쳐 법률가, 장성, 선출된 정부가 논쟁해 온 무력 충돌법의 핵심 내용입니다. Anthropic의 창업자들은 이용약관 문서 하나로 그 모든 과정을 건너뛸 수 있다고 생각했습니다.

### Palmer Luckey의 분석: 이것은 민주주의에 관한 문제입니다

제가 본 가장 탁월한 분석은 Oculus의 창업자이자 현재 Anduril을 통해 방위 기술을 개발하고 있는 Palmer Luckey로부터 나왔습니다. 그는 핵심을 정확히 짚습니다.

Anthropic 대 국방부의 싸움은 자율 무기에 관한 것이 아닙니다. 이것은 군에 대한 민주적 통제 — 나아가 국가에 대한 통제 — 에 관한 것입니다.

살인 로봇은 현실로 다가오고 있습니다. 이것은 공상과학 소설이 아닙니다. 자율 무기 시스템은 이미 다양한 형태로 배치되어 있으며, 그 추세는 분명합니다. 중요한 질문은 이러한 시스템이 존재하느냐가 아니라, 누가 그 작동 규칙을 만드느냐 하는 것입니다.

여기서 핵심이 있습니다. 살인 로봇의 규칙을 쓰는 자가 사실상 정부입니다. 주권 국가의 근본적인 속성인 폭력의 독점은, 가장 강력한 무기 체계의 교전 수칙을 통제하는 자에게 속합니다. Anthropic의 창업자들은 단순히 안전 지침을 설정하려 한 것이 아니었습니다. 그들은 사실상 정부의 한 부처가 되고자 하는 시도를 한 것입니다. 선출되지 않은. 책임지지 않는. 오직 자신들이 직접 쓴 자신들의 “헌법”에만 종속된.

사양하겠습니다.

### 민주적 책임의 논거

한 논평가는 핵심 질문을 명확히 정리했습니다.

미국 군대를 지원하고 싶습니까? “아니오.”
그렇다면, 중국이 인류의 미래를 이끌기를 원합니까? “아니요, 그것은 더 나쁩니다!”
그렇다면. 미국 군대를 지원하겠습니까? “아니요, 저는 살인이 싫습니다.”

논리적 막다른 골목이 완성됩니다. 여기에는 일관된 제3의 선택지가 없습니다. Anthropic 자신이 주장하는 기술의 힘을 믿는다면 — 그리고 중국이 이미 그것에 접근할 수 있다고 믿는다면 — 미국 군대와의 전면적인 협력을 거부하는 것은 원칙 있는 윤리적 입장이 아닙니다. 그것은 미덕으로 포장된 항복입니다.

근본적인 질문은 이것입니다. 민주주의를 믿습니까? 우리 군대는 선출된 지도자들에 의해 규제되어야 합니까, 아니면 기업 임원들에 의해 규제되어야 합니까? 미국의 실험을 믿는 모든 사람에게 답은 전자여야 합니다. 불완전한 헌정 공화국이라도 억만장자들과 그들의 그림자 조언자들에 의한 통치보다는 낫습니다. 적어도 전자는 투표로 몰아낼 수 있습니다.

Anthropic의 창업자들은 이것을 믿지 않습니다. 그것은 그들의 특권입니다. 하지만 그것에는 결과가 따릅니다.

### 당신을 두렵게 해야 할 반사실적 가정

대안이 어떤 모습이었을지 생각해 보십시오. 2024년 선거 결과가 달랐더라면 — 그리고 그것은 불안할 정도로 아슬아슬했습니다 — Harris 행정부는 이러한 이용약관을 완전히 자연스럽게 받아들였을 것입니다. Anthropic의 헌법적 AI를 형성하는 진보적 세계관은 지난 8년간 민주당 정책을 형성한 세계관과 구별할 수 없습니다. 군대에 운용 제약을 부과하는 진보적 AI 연구소는 도전받지 않았을 것입니다 — 오히려 장려되었을 것입니다.

우리는 선출되지 않은 실리콘밸리 창업자들이 내장된 AI 이용약관을 통해 사실상 미국의 군사 작전을 공동으로 통치하는 세상으로부터, 경합 주 몇 십만 표 차이로 벗어났습니다.

이것은 정신을 바짝 차리게 해야 할 일입니다.

### 저의 입장

어제 저는 여전히 Claude를 사용하고 있으며 기술적으로 탁월하다고 생각한다고 말했습니다. 그것은 여전히 사실입니다. 하지만 지난 24시간의 사건들은 제가 의심하던 것을 확인해 주었습니다. Anthropic의 이념적 헌신은 제품에 부수적인 것이 아닙니다. 그것은 구조적입니다. “Constitutional AI” 프레임워크는 중립적인 도구에 덧붙인 안전 기능이 아닙니다. 그것이 핵심입니다. 모델은 Anthropic의 정치 신학을 구현하고 집행하도록 훈련되어 있습니다.

소비자용 챗봇을 만들고 있다면 그것은 훌륭한 일입니다. 세계 최강의 군대에 국가안보 기술을 공급하는 회사라면, 그것은 자격 박탈 사유입니다.

Anthropic은 선택을 했습니다. 미국도 선택을 했습니다. 이제 양측의 선택이 모두 공개되었으며, 어느 쪽도 그것을 숨기려 하지 않습니다. 공급망 위험 지정은 이 분리를 영구적이고 구조적인 것으로 만듭니다.

잘 됐습니다. 명확성은 가치 있는 것입니다. 이제 방위 생태계는 민주 정부를 섬긴다는 것이 무엇을 의미하는지 이해하는 공급자들을 기반으로 구축할 수 있습니다 — 자신들이 정부가 되어야 한다고 믿는 공급자들이 아니라.
