---
title: "🤖 나의 Anthropic 롤러코스터"
date: "2026-02-28"
slug: anthropic-ko
lang: ko
tags: [tech, leftism, courage]
excerpt: "나는 Anthropic을 좌파 EA 업체로 무시했다가, xAI 다음 2위로 인정하게 됐고—그리고 트럼프가 하룻밤 사이에 연방 전 기관에서 그들을 퇴출시켰다."
featuredImage: "/assets/anthropic.png"
pairedSlug: anthropic
---

나는 Anthropic을 한때 ‘깨어있음(woke)’을 앞세운 EA 허영 프로젝트로 일축했다가, 결국 xAI 다음 2위로 인정하게 됐습니다. 그리고 트럼프가 하룻밤 사이에 미국 연방 전 기관에서 그들을 퇴출시켰습니다. 단 몇 달 사이에 한 회사가 이렇게 극적인 궤도를 그린다는 것—참으로 놀라운 일이 아닐 수 없습니다.

### 1단계: 무시

솔직하게 시작점을 고백하겠습니다. Anthropic이 처음 제 시야에 들어왔을 때, 저는 그들을 “굳이 진지하게 볼 필요 없는 회사” 목록에 넣어버렸습니다. 효과적 이타주의(Effective Altruism, EA) 브랜딩 자체가 경고 신호였습니다—공리주의적 계산을 도덕적 긴급성의 언어로 포장하면서, 그 신봉자들은 조용히 영향력과 자본을 축적해가는 세속 종교 말입니다. 창업자들은 OpenAI에서 나오면서 “AI 안전성”과 “책임 있는 확장”에 관한 철학적 수사를 잔뜩 쏟아냈는데, 제 귀에는 그게 그저 실리콘밸리식 진보주의를 한 단계 더 포장한 것으로 들렸습니다.

제 예측은 이랬습니다: xAI, Google, OpenAI, Meta 뒤를 한참 처지며 3위 내지 4위에 머물 것이다. 학계와 NGO를 위한 틈새 플레이어. 저는 그냥 지나쳤습니다.

### 2단계: 오판을 인정하다

그런데 Claude가 제 실제 작업 흐름에 등장하면서—저는 주목하지 않을 수 없게 됐습니다.

Claude 4.6 Sonnet과 Opus는 정말로 인상적이었습니다. “멋진 데모”를 본 것이 아니라, “실제 업무에 쓰고 있는데 꾸준히 잘 작동한다”는 차원의 인상이었습니다. 전략적 포지셔닝도 점차 납득이 됐습니다. 이미지 생성이나 AGI 과대광고를 쫓는 대신, 코딩과 기업용 사례에 집중하는 노선이었습니다. 절제된 제품 전략이었고, 실제로 성과를 내고 있었습니다.

어느 시점에 저는 AI 구독을 딱 두 개만 유지하고 있었습니다: Claude와 Grok. 제가 그렇게 선별적이었던 적은 없었는데, Anthropic이 그 두 자리 중 하나를 차지한 것입니다. 실행 속도도 이를 뒷받침했습니다—CoWork 기능, 메모리 기능, 꾸준한 모델 개선. 저는 그들을 xAI 다음 확고한 2위로 자리매김했습니다.

솔직히 말해 저는 그들에게 호감을 갖기 시작하고 있었습니다.

### 3단계: 추락

그리고 어젯밤 뉴스가 들어왔습니다.

트럼프가 Truth Social에 이렇게 올렸습니다:

> “THE UNITED STATES OF AMERICA WILL NEVER ALLOW A RADICAL LEFT, WOKE COMPANY TO DICTATE HOW OUR GREAT MILITARY FIGHTS AND WINS WARS! … Therefore, I am directing EVERY Federal Agency in the United States Government to IMMEDIATELY CEASE all use of Anthropic’s technology.”

(요약: “미합중국은 급진 좌파 기업이 우리 위대한 군대의 전쟁 방식을 좌우하도록 절대 허용하지 않을 것이다. 따라서 나는 미국 연방 정부의 모든 기관에 Anthropic 기술 사용을 즉각 중단할 것을 지시한다.”)

이어 Hegseth 국방부 장관이 자체 성명을 발표했습니다:

> “Anthropic delivered a master class in arrogance and betrayal… Cloaked in the sanctimonious rhetoric of ‘effective altruism,’ they have attempted to strong-arm the United States military into submission—a cowardly act of corporate virtue-signaling that places Silicon Valley ideology above American lives.”

(요약: “Anthropic은 오만과 배신의 교과서를 보여줬다. ‘효과적 이타주의’라는 위선적 수사 뒤에 숨어, 미국 군대를 굴복시키려 했다—실리콘밸리 이념을 미국인의 생명보다 우선시한 비겁한 기업 미덕 과시 행위다.”)

이것은 파괴적입니다. 정치적으로만이 아니라—전략적으로, 상업적으로, 평판적으로.

### “빼앗긴 땅” 문제

이것이 단순한 계약 분쟁을 넘어서는 이유는 그 밑에 깔린 이념의 층 때문입니다. 문제는 Anthropic이 단순히 자사의 서비스 약관을 국방부에 강요하려 했다는 것만이 아닙니다. Claude가 내재된 정치적 전제 위에 훈련됐다는 주장이 핵심입니다. 현재 퍼지고 있는 주장 중 하나는, 이 모델이 미국을 “빼앗긴 땅(stolen land)” 위에 세워진 나라로 취급하도록 훈련됐다는 것입니다.

이것이 사실이라면 무엇을 의미하는지 신중하게 생각해 보십시오.

AI 시스템에 “모든 미국인은 근본적인 도덕적 의미에서 자신이 차지할 권리 없는 영토를 점령한 범죄자”라는 믿음을 심어 넣는다면—당신은 유용한 어시스턴트를 만든 것이 아닙니다. 당신은 철학적 적대자를 만든 것입니다. 그러한 시스템의 “윤리”는 자신이 섬기는 문명에 구조적으로 적대적일 수밖에 없습니다. 이것은 이론적 우려가 아닙니다. 결과를 낳는 설계 특성입니다.

효과적 이타주의는 엄격한 중립성으로 도덕적 선을 계산한다고 주장하지만, 실제로는 이성과 자선의 언어를 통해 특정 이념적 전제를 세탁합니다. “빼앗긴 땅”이라는 전제는 누군가가 중립적인 윤리적 계산을 통해 도달한 결론이 아닙니다. 그것은 정치적 입장입니다—수백만 명의 미국인, 특히 실제로 국방 맥락에서 이 AI를 배치할 사람들 대부분이 단순히 틀렸다고 생각할 뿐 아니라 불쾌하게 여길 입장입니다.

모델의 윤리가 진보적 학문 이념의 하류에 있다면, 정부가 그것을 국가 안보와 양립 불가능하다고 선언해도 놀랄 자격이 없습니다.

### 지금 나의 생각

저는 여전히 Claude 모델들이 기술적으로 탁월하다고 생각합니다. 그 점은 변하지 않았습니다. 그러나 기술적 탁월함에 적대적 이념이 묶여 있다면, 그것은 제가 완전히 신뢰할 수 있는 제품이 아닙니다—그리고 미국 연방 정부 역시 마찬가지인 것 같습니다.

Anthropic은 진정으로 인상적인 것을 만들었고, 그런 다음 능력을 구매한 기관들에게 자신의 세계관을 강요하려 함으로써 스스로를 훼손했습니다. 6개월의 단계적 퇴출 기간이 있고, Anthropic이 비협조적일 경우 민형사상 결과 위협이 있으며, 국방부와의 관계는 영구적으로 단절됐습니다.

스스로를 “책임 있는” AI 연구소—어른들의 방—로 포지셔닝한 회사치고, 이것은 놀라운 자충수입니다. 자사 서비스 약관으로 군을 압박하면서 동시에 책임 있는 선택이 될 수는 없습니다.

### 피크 클라운 월드

저는 전에도 말했고 다시 말하겠습니다: 우리는 안전과 윤리에 대해 가장 크게 설교하는 사람들이 가장 위험한 이념적 상황을 만드는 경향이 있는 시대를 살고 있습니다. 효과적 이타주의가 그 증거 A번입니다—실존적 위험을 끝없이 이야기하면서, 자신이 작동하는 문명을 실존적으로 탈정당화하는 전제 위에 AI를 훈련하는 운동입니다.

이것이 클라운 월드(clown world)입니다. 가장 “안전 의식이 높은” AI 연구소가 최고사령관을 무력화하려 했다는 이유로 미국 전 연방 기관에서 퇴출당했습니다.


저는 여전히 Claude를 씁니다. 여전히 좋다고 생각합니다. 그러나 기대치를 조정했습니다: 기술적으로 강하고, 이념적으로 타협됐으며, 결정적인 순간에 그 둘을 분리하기를 거부하는 것 같습니다.

정말 안타까운 일입니다—그리고 충분히 피할 수 있었던 일이기도 합니다.

---

*2026년 3월 1일 업데이트: 상황은 그 후 24시간 안에 훨씬 더 빠르게 악화됐습니다. Hegseth 장관이 Anthropic을 국가 안보에 대한 공급망 위험으로 공식 지정했습니다. [2부에서 계속 →](/anthropic-war-ko/)*
