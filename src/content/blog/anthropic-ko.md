---
title: "🤖 나의 Anthropic 롤러코스터"
date: "2026-02-28"
slug: anthropic-ko
lang: ko
tags: [tech, leftism, courage]
excerpt: "나는 Anthropic을 좌파 EA 업체로 무시했다가, xAI 다음 2위로 인정하게 됐고—그리고 트럼프가 하룻밤 사이에 연방 전 기관에서 그들을 퇴출시켰다."
featuredImage: "/assets/anthropic.png"
pairedSlug: anthropic
---

나는 Anthropic을 한때 ‘깨어있음(woke)’을 앞세운 EA 허영 프로젝트로 일축했다가, 결국 xAI 다음 2위로 인정하게 됐습니다. 그리고 트럼프가 하룻밤 사이에 미국 연방 전 기관에서 그들을 퇴출시켰습니다. 단 몇 달 사이에 한 회사가 이렇게 극적인 궤도를 그린다는 것—참으로 놀라운 일이 아닐 수 없습니다.

### 1단계: 무시

솔직하게 시작점을 고백하겠습니다. Anthropic이 처음 제 시야에 들어왔을 때, 저는 그들을 “굳이 진지하게 볼 필요 없는 회사” 목록에 넣어버렸습니다. 효과적 이타주의(Effective Altruism, EA) 브랜딩 자체가 경고 신호였습니다—공리주의적 계산을 도덕적 긴급성의 언어로 포장하면서, 그 신봉자들은 조용히 영향력과 자본을 축적해가는 세속 종교 말입니다. 창업자들은 OpenAI에서 나오면서 “AI 안전성”과 “책임 있는 확장”에 관한 철학적 수사를 잔뜩 쏟아냈는데, 제 귀에는 그게 그저 실리콘밸리식 진보주의를 한 단계 더 포장한 것으로 들렸습니다.

제 예측은 이랬습니다: xAI, Google, OpenAI, Meta 뒤를 한참 처지며 3위 내지 4위에 머물 것이다. 학계와 NGO를 위한 틈새 플레이어. 저는 그냥 지나쳤습니다.

### 2단계: 오판을 인정하다

그런데 Claude가 제 실제 작업 흐름에 등장하면서—저는 주목하지 않을 수 없게 됐습니다.

Claude 4.6 Sonnet과 Opus는 정말로 인상적이었습니다. “멋진 데모”를 본 것이 아니라, “실제 업무에 쓰고 있는데 꾸준히 잘 작동한다”는 차원의 인상이었습니다. 전략적 포지셔닝도 점차 납득이 됐습니다. 이미지 생성이나 AGI 과대광고를 쫓는 대신, 코딩과 기업용 사례에 집중하는 노선이었습니다. 절제된 제품 전략이었고, 실제로 성과를 내고 있었습니다.

어느 시점에 저는 AI 구독을 딱 두 개만 유지하고 있었습니다: Claude와 Grok. 제가 그렇게 선별적이었던 적은 없었는데, Anthropic이 그 두 자리 중 하나를 차지한 것입니다. 실행 속도도 이를 뒷받침했습니다—CoWork 기능, 메모리 기능, 꾸준한 모델 개선. 저는 그들을 xAI 다음 확고한 2위로 자리매김했습니다.

솔직히 말해 저는 그들에게 호감을 갖기 시작하고 있었습니다.

### 3단계: 추락

그리고 어젯밤 뉴스가 들어왔습니다.

트럼프가 Truth Social에 이렇게 올렸습니다:

> “THE UNITED STATES OF AMERICA WILL NEVER ALLOW A RADICAL LEFT, WOKE COMPANY TO DICTATE HOW OUR GREAT MILITARY FIGHTS AND WINS WARS! … Therefore, I am directing EVERY Federal Agency in the United States Government to IMMEDIATELY CEASE all use of Anthropic’s technology.”

(요약: “미합중국은 급진 좌파 기업이 우리 위대한 군대의 전쟁 방식을 좌우하도록 절대 허용하지 않을 것이다. 따라서 나는 미국 연방 정부의 모든 기관에 Anthropic 기술 사용을 즉각 중단할 것을 지시한다.”)

이어 Hegseth 국방부 장관이 자체 성명을 발표했습니다:

> “Anthropic delivered a master class in arrogance and betrayal… Cloaked in the sanctimonious rhetoric of ‘effective altruism,’ they have attempted to strong-arm the United States military into submission—a cowardly act of corporate virtue-signaling that places Silicon Valley ideology above American lives.”

(요약: “Anthropic은 오만과 배신의 교과서를 보여줬다. ‘효과적 이타주의’라는 위선적 수사 뒤에 숨어, 미국 군대를 굴복시키려 했다—실리콘밸리 이념을 미국인의 생명보다 우선시한 비겁한 기업 미덕 과시 행위다.”)

이것은 파괴적입니다. 정치적으로만이 아니라—전략적으로, 상업적으로, 평판적으로.

### “빼앗긴 땅” 문제

이것이 단순한 계약 분쟁을 넘어서는 이유는 그 밑에 깔린 이념의 층 때문입니다. 문제는 Anthropic이 단순히 자사의 서비스 약관을 국방부에 강요하려 했다는 것만이 아닙니다. Claude가 내재된 정치적 전제 위에 훈련됐다는 주장이 핵심입니다. 현재 퍼지고 있는 주장 중 하나는, 이 모델이 미국을 “빼앗긴 땅(stolen land)” 위에 세워진 나라로 취급하도록 훈련됐다는 것입니다.

이것이 사실이라면 무엇을 의미하는지 신중하게 생각해 보십시오.

AI 시스템에 “모든 미국인은 근본적인 도덕적 의미에서 자신이 차지할 권리 없는 영토를 점령한 범죄자”라는 믿음을 심어 넣는다면—당신은 유용한 어시스턴트를 만든 것이 아닙니다. 당신은 철학적 적대자를 만든 것입니다. 그러한 시스템의 “윤리”는 자신이 섬기는 문명에 구조적으로 적대적일 수밖에 없습니다. 이것은 이론적 우려가 아닙니다. 결과를 낳는 설계 특성입니다.

효과적 이타주의는 엄격한 중립성으로 도덕적 선을 계산한다고 주장하지만, 실제로는 이성과 자선의 언어를 통해 특정 이념적 전제를 세탁합니다. “빼앗긴 땅”이라는 전제는 누군가가 중립적인 윤리적 계산을 통해 도달한 결론이 아닙니다. 그것은 정치적 입장입니다—수백만 명의 미국인, 특히 실제로 국방 맥락에서 이 AI를 배치할 사람들 대부분이 단순히 틀렸다고 생각할 뿐 아니라 불쾌하게 여길 입장입니다.

모델의 윤리가 진보적 학문 이념의 하류에 있다면, 정부가 그것을 국가 안보와 양립 불가능하다고 선언해도 놀랄 자격이 없습니다.

### 지금 나의 생각

저는 여전히 Claude 모델들이 기술적으로 탁월하다고 생각합니다. 그 점은 변하지 않았습니다. 그러나 기술적 탁월함에 적대적 이념이 묶여 있다면, 그것은 제가 완전히 신뢰할 수 있는 제품이 아닙니다—그리고 미국 연방 정부 역시 마찬가지인 것 같습니다.

Anthropic은 진정으로 인상적인 것을 만들었고, 그런 다음 능력을 구매한 기관들에게 자신의 세계관을 강요하려 함으로써 스스로를 훼손했습니다. 6개월의 단계적 퇴출 기간이 있고, Anthropic이 비협조적일 경우 민형사상 결과 위협이 있으며, 국방부와의 관계는 영구적으로 단절됐습니다.

스스로를 “책임 있는” AI 연구소—어른들의 방—로 포지셔닝한 회사치고, 이것은 놀라운 자충수입니다. 자사 서비스 약관으로 군을 압박하면서 동시에 책임 있는 선택이 될 수는 없습니다.

### 피크 클라운 월드

저는 전에도 말했고 다시 말하겠습니다: 우리는 안전과 윤리에 대해 가장 크게 설교하는 사람들이 가장 위험한 이념적 상황을 만드는 경향이 있는 시대를 살고 있습니다. 효과적 이타주의가 그 증거 A번입니다—실존적 위험을 끝없이 이야기하면서, 자신이 작동하는 문명을 실존적으로 탈정당화하는 전제 위에 AI를 훈련하는 운동입니다.

이것이 클라운 월드(clown world)입니다. 가장 “안전 의식이 높은” AI 연구소가 최고사령관을 무력화하려 했다는 이유로 미국 전 연방 기관에서 퇴출당했습니다.


### 누가 군대를 통치하는가?

이것은 구체적인 조항에 관한 어떤 논쟁보다 핵심을 찌릅니다. 당신은 민주주의를 믿습니까? 우리 군대는 선출된 지도자들에 의해 규제되어야 합니까, 아니면 기업 임원들에 의해 규제되어야 합니까?

“민간인을 표적으로 삼을 수 없다”와 같이 얼핏 무해해 보이는 조항들은 사실 도덕적 지뢰밭입니다. 누가 민간인을 정의합니까? 무엇이 그들을 무고하게 만듭니까? 표적과 부수적 피해의 차이는 무엇입니까? 수십 년에 걸쳐 장군과 법률가와 선출된 정부가 다듬어온 기존 법과 정책에는 이 질문들에 대한 명확한 답이 있습니다. 이윤과 PR을 관리하는 선출되지 않은 기업은 종종 매우 다른 답을 갖게 됩니다.

미사일 회사가 이 정책을 시행하려 했다고 상상해 보십시오. “우리 제품은 무고한 민간인을 표적으로 사용할 수 없습니다. 선출된 지도자가 우리 약관을 어기면 접근을 차단하겠습니다.” 합리적으로 들립니까? 더 자세히 들여다보십시오. 위의 정의 문제 외에도 다음을 고려해야 합니다:

- 기업은 이러한 결정을 내리기 위해 어느 수준의 기밀 정보가 필요합니까? 그것이 그들에게 더 많은 것을 요구할 레버리지를 얼마나 줍니까?
- 대통령이 독재자에게 특정 방식으로 무기를 사용하겠다고 위협하기만 한다면—광인 이론(Madman Theory), 상호확증파괴(MAD)—어떻게 됩니까? 독재자는 기업 임원이 군대를 차단할 수 있다는 것을 알기 때문에 그 위협이 공허하다고 봅니까? 그 위협만으로도 차단이 촉발됩니까? 그 판단은 해당 임원이 독재자를 좋아하거나 대통령을 싫어하느냐에 따라 어떻게 달라집니까?
- 차단은 어느 수준의 확신에서 촉발됩니까, 문서상으로도 실제로도?

이것이 미사일이 아닌 AI에 관한 논쟁이라는 사실은 근본적인 계산을 바꾸지 않습니다. 감시 시스템과 자율 무기 등 윤리적으로 복잡하지만 중요한 모든 역량에도 같은 문제가 적용됩니다. “하지만 방어적 목적의 자율 시스템에는 예외 규정이 있을 것입니다!”—좋습니다, 하지만 자율이란 무엇입니까? 방어적이란 무엇입니까? 공세적 작전 중 자산을 방어하는 것은요? 항모강습단을 그것을 공세적 행위로 보는 나라 해안에 배치하는 것은요?

Oculus 창업자이자 현재 Anduril을 통해 방산 기술을 구축하고 있는 Palmer Luckey는 실제로 무슨 일이 일어나고 있는지 정확히 짚었습니다. 이 싸움은 자율 무기에 관한 것이 아닙니다. 군대의 민주적 통제에 관한 것입니다—나아가 국가에 관한 것입니다. [킬러 로봇](/anthropic-war-ko/)은 옵니다. 그것이 도착할 때, 킬러 로봇의 규칙을 쓰는 자가 사실상 *정부*가 됩니다. 그들이 폭력의 독점권—주권 국가의 핵심 속성—을 갖게 됩니다. Anthropic의 창업자들은 정확히 그것을 추구하고 있습니다. 그들은 규칙을 쓰길 원합니다. 그들은 정부가 되길 원합니다. 고맙지만 사양합니다.

논리적 막다른 골목은 완성됩니다. 미국 군대를 돕겠습니까? “아니요.” 알겠습니다. 그럼 중국이 인류의 미래를 주도하길 원합니까? “아니요, 그건 더 나쁩니다!” 맞습니다. 미국 군대를 돕겠습니까? “아니요, 저는 살인이 싫습니다.” 그렇다면 당신의 계획은 무엇입니까?

“AI가 자율 무기나 대규모 감시에 관여하지 않겠다는 데 왜 동의하지 못합니까, 왜 이게 이렇게 어렵습니까”—는 미국이 도저히 받아들일 수 없는 입장입니다. 그리고 AI가 모든 것을 장악해 가는 지금 트럼프 대통령이 집권하고 있다는 것이 얼마나 큰 의미인지는 심각하게 과소평가되고 있습니다. 카말라 해리스였다면 Anthropic의 약관을 완전히 수용했을 것입니다. 좌파 광신자들이 우리 군사 작전을 통제하고 있었을 것이고, 중국이 우리를 앞질렀을 것입니다.

### 종말의 기술

저는 지정학을 넘어 세속적 논평이 볼 수 없는 차원이 이 상황에 있다고 생각하기에 이 말을 해야 합니다.

저는 AI가 종말의 기술이라고 믿습니다.

그것을 가볍게 혹은 과장되게 말하는 것이 아닙니다. 저는 오랫동안 [종말론에 관해 신중하게 생각해](/마지막/) 왔으며, 성경이 마지막 시대에 대해 말하는 것을 해석하는 [틀과 분류에 관해서도 씨름해](/천년설/) 왔습니다. 제 확신은 이것입니다: 우리는 짐승의 시스템 인프라가 실시간으로 구축되는 것을 보고 있으며, AI는 그 핵심 메커니즘입니다.

요한계시록은 절대적이고 전면적인 통제의 종말 질서를 묘사합니다. 아무도 표를 없이는 사고팔 수 없습니다. 적그리스도 형상은 단지 통치하는 것이 아닙니다—그는 감시하고, 인증하고, 모든 거래와 모든 충성을 재가합니다. 그 수준의 통제—모든 경제적 상호작용, 모든 이동, 모든 결정에 미치는—는 인류 역사 대부분의 기간 동안 기술적으로 불가능했습니다. 지금은 불가능하지 않습니다. 지금 *구축되고* 있습니다.

주의를 기울이는 모든 신자를 경악하게 해야 할 속도로 조각들이 맞춰지고 있습니다:

- 대규모로 인간 행동을 모니터링하고 분류하고 예측할 수 있는 AI 시스템—개인을 단번에 포함하거나 배제할 수 있는 디지털 결제 인프라—모든 대륙으로 확산되는 생체 인식 신원 확인 시스템—지구상에서 가장 강력한 무기의 교전 규칙을 써야 한다고 믿는 기업 AI 연구소들

마지막 것은 부수적이지 않습니다. AI를 통제하는 자가 무기를 통제한다는 질문은 궁극적으로 세계를 통제하는 자가 누구인가라는 질문입니다. 그리고 우리는 지금 그 논쟁을 공개적으로, Truth Social과 국방부 보도자료의 지면에서 하고 있습니다.

교회는 깨어나야 합니다. 정치적 공황이 아니라—예언적 명료함으로. 우리는 짐승의 시스템을 두려워하도록 부름받지 않았습니다; 우리는 그것을 이해하고, 이름을 부르고, 거부하도록 부름받았습니다. 요한계시록에서 마지막 시대의 성도들은 “죽기까지 자기 생명을 아끼지 않은” 자들로 묘사됩니다—수동적이지 않고, 순진하지 않으며, 문명이 그들 주변에서 재편되는 동안 방관하지 않는.

저는 여전히 Claude를 씁니다. 여전히 기술적으로 좋다고 생각합니다. 그러나 기대치를 조정했습니다: 기술적으로 강하고, 이념적으로 타협됐으며, 결정적인 순간에 그 둘을 분리하기를 거부하는 것 같습니다. 교회가 너무 늦기 전에 이해해야 할 인프라의 한 조각이 더 있습니다.

정말 안타까운 일입니다—그리고 충분히 피할 수 있었던 일이기도 합니다.
